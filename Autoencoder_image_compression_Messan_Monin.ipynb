{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder_image_compression_Messan_Monin.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4CZrC0gXjPk"
      },
      "source": [
        "### Building the encoder\n",
        "We're going to use the MNIST dataset where the size of each image is 28x28. \n",
        "We set the shape to (784) rather than (28, 28) because we're going to use only dense layers in the network and thus the input must be in the form of a vector, not a matrix.\n",
        "We are gonna implement a model containing the following layers:\n",
        "\n",
        "*   `Dense` layer with 300 neurons\n",
        "*   `LeakyReLU` layer\n",
        "*   `Dense` layer with 2 neurons\n",
        "*   `LeakyReLU` layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwKeIsD9OlvS"
      },
      "source": [
        "import tensorflow.keras.layers\n",
        "import tensorflow.keras.models\n",
        "\n",
        "x = tensorflow.keras.layers.Input(shape=(784), name=\"encoder_input\")\n",
        "\n",
        "encoder_dense_layer1 = tensorflow.keras.layers.Dense(units=300, name=\"encoder_dense_1\")(x)\n",
        "encoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_1\")(encoder_dense_layer1)\n",
        "\n",
        "encoder_dense_layer2 = tensorflow.keras.layers.Dense(units=2, name=\"encoder_dense_2\")(encoder_activ_layer1)#to do\n",
        "encoder_output = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_2\")(encoder_dense_layer2) #to do"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ssk5DxEfYUck"
      },
      "source": [
        "Build the encoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oi2DUdtOtqu"
      },
      "source": [
        "encoder = tensorflow.keras.models.Model(x, encoder_output, name=\"encoder_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrTh_O-oYZU9"
      },
      "source": [
        "We can print a summary of the encoder's architecture:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTP93VTzYjnQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "4dcfc2e4-cf2d-470a-c1a4-14ce2e741f75"
      },
      "source": [
        "encoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_1 (Dense)      (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_1 (LeakyRe (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_2 (Dense)      (None, 2)                 602       \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_2 (LeakyRe (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 236,102\n",
            "Trainable params: 236,102\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U5X8ySIYt7K"
      },
      "source": [
        "### Building the decoder\n",
        "Because the input layer of the decoder accepts the output returned from the last layer in the encoder, we have to make sure these 2 layers match in the size. The last layer in the encoder returns a vector of 2 elements and thus the input of the decoder must have 2 neurons. You can easily note that the layers of the decoder are just reflection to those in the encoder.\n",
        "\n",
        "After the input layer, our decoder model should contain the following layers:\n",
        "*   `Dense` layer with 300 neurons\n",
        "*   `LeakyReLU` layer\n",
        "*   `Dense` layer with 784 neurons\n",
        "*   `LeakyReLU` layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRCL1pqLOt33"
      },
      "source": [
        "decoder_input = tensorflow.keras.layers.Input(shape=(2), name=\"decoder_input\")\n",
        "\n",
        "decoder_dense_layer1 = tensorflow.keras.layers.Dense(units=300, name=\"decoder_dense_1\")(decoder_input) #to do\n",
        "decoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_1\")(decoder_dense_layer1) #to do\n",
        "decoder_dense_layer2 = tensorflow.keras.layers.Dense(units=784, name=\"decoder_dense_2\")(decoder_activ_layer1) #to do\n",
        "decoder_output = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_2\")(decoder_dense_layer2) #to do"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmYj0gBaY9lH"
      },
      "source": [
        "Build de decoder model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-qKTXyNOt6m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "666cf085-6680-439d-9554-c7a63373614d"
      },
      "source": [
        "decoder = tensorflow.keras.models.Model(decoder_input, decoder_output, name=\"decoder_model\")\n",
        "decoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"decoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_1 (Dense)      (None, 300)               900       \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_1 (LeakyRe (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_2 (Dense)      (None, 784)               235984    \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_2 (LeakyRe (None, 784)               0         \n",
            "=================================================================\n",
            "Total params: 236,884\n",
            "Trainable params: 236,884\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC301so4ZLzQ"
      },
      "source": [
        "### Build the complete autoencoder\n",
        "The tensor named `ae_input` represents the input layer that accepts a vector of length 784. This tensor is fed to the encoder model as an input. The output from the encoder is saved in `ae_encoder_output` which is then fed to the decoder. Finally, the output of the autoencoder is saved in `ae_decoder_output`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPpWaFnaOt8u"
      },
      "source": [
        "ae_input = tensorflow.keras.layers.Input(shape=(784), name=\"AE_input\")\n",
        "ae_encoder_output = encoder(ae_input)\n",
        "ae_decoder_output = decoder( ae_encoder_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAjGQiOCpZFe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "5d9dc198-e2ea-4678-c706-7d8b5fbf0c45"
      },
      "source": [
        "ae = tensorflow.keras.models.Model(ae_input, ae_decoder_output, name=\"AE\")\n",
        "ae.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"AE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "AE_input (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_model (Functional)   (None, 2)                 236102    \n",
            "_________________________________________________________________\n",
            "decoder_model (Functional)   (None, 784)               236884    \n",
            "=================================================================\n",
            "Total params: 472,986\n",
            "Trainable params: 472,986\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjkAWouqcWBq"
      },
      "source": [
        "### Compile autoencoder model.\n",
        "We want to use the mean square error as loss function and Adam optimizer with learning rate set to 0.0005. For that we will use the `compile()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nS2S_DxyOt_i"
      },
      "source": [
        "import tensorflow.keras.optimizers  \n",
        "ae.compile(loss='mse', optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.0005))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MruvDLeSctxR"
      },
      "source": [
        "### Load Dataset\n",
        "We are going to use the MNIST dataset that can be loaded from the datasets Keras API. The dataset is loaded as NumPy arrays representing the training data, test data, train labels, and test labels. Note that we are not interested in using the class labels at all while training the model but they are just used to display the results. \\\\\n",
        "Because our model accepts the images as vectors of length 784, we must reshape the the images from the dataset into 1D vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvsBcXeSOuBX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3faa33b2-ecb5-446f-9b03-66fd20eb6651"
      },
      "source": [
        "import tensorflow.keras.datasets\n",
        "import numpy\n",
        "\n",
        "(x_train_orig, y_train), (x_test_orig, y_test) = tensorflow.keras.datasets.mnist.load_data()\n",
        "x_train_orig = x_train_orig.astype(\"float32\") / 255.0\n",
        "x_test_orig = x_test_orig.astype(\"float32\") / 255.0\n",
        "\n",
        "x_train = numpy.reshape(x_train_orig, newshape=(x_train_orig.shape[0], numpy.prod(x_train_orig.shape[1:])))\n",
        "x_test = numpy.reshape(x_test_orig, newshape=(x_test_orig.shape[0], numpy.prod(x_test_orig.shape[1:])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChYx1rHgds7o"
      },
      "source": [
        "### Train the autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xsZ-idudsLE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "3c1e1b0c-093b-4f94-a6bd-fd4b2bf1eb25"
      },
      "source": [
        "ae.fit(x_train, x_train, epochs=20, batch_size=256, shuffle=True, validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0599 - val_loss: 0.0552\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0546 - val_loss: 0.0540\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0535 - val_loss: 0.0530\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0525 - val_loss: 0.0521\n",
            "Epoch 5/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0513 - val_loss: 0.0506\n",
            "Epoch 6/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0498 - val_loss: 0.0490\n",
            "Epoch 7/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0485 - val_loss: 0.0482\n",
            "Epoch 8/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0476 - val_loss: 0.0475\n",
            "Epoch 9/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0471 - val_loss: 0.0470\n",
            "Epoch 10/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0467 - val_loss: 0.0466\n",
            "Epoch 11/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0464 - val_loss: 0.0463\n",
            "Epoch 12/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0461 - val_loss: 0.0462\n",
            "Epoch 13/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0459 - val_loss: 0.0459\n",
            "Epoch 14/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0457 - val_loss: 0.0457\n",
            "Epoch 15/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0455 - val_loss: 0.0455\n",
            "Epoch 16/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0453 - val_loss: 0.0454\n",
            "Epoch 17/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0452 - val_loss: 0.0453\n",
            "Epoch 18/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0450 - val_loss: 0.0452\n",
            "Epoch 19/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0449 - val_loss: 0.0450\n",
            "Epoch 20/20\n",
            "235/235 [==============================] - 5s 20ms/step - loss: 0.0447 - val_loss: 0.0448\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f33ba0027b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRnbfmvafdkj"
      },
      "source": [
        "### Make predictions\n",
        "The `predict()` method is used in the next code to return the outputs of both the encoder and decoder models. The `encoded_images` NumPy array holds the reshaped 1D vectors representing all training images obtained from the MNIST dataset. The decoder model accepts the output of the encoder to reconstruct the original images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7SoKGz_OuDj"
      },
      "source": [
        "encoded_images = encoder.predict(x_train)\n",
        "decoded_images = decoder.predict(encoded_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqdv4Lzsnv95"
      },
      "source": [
        "As we can see below, the variable `encoded_images` contains a compressed representation of each sample. While input images were represented as a 1D vector of length 784, each sample is represented after compression by a 1D vector of length 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7ci710Jn2N0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6a32776c-3df1-4769-c8ba-fc4da1dd4c6b"
      },
      "source": [
        "encoded_images[1].size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ltO3RVAg0ii"
      },
      "source": [
        "After decoding, vectors show a length of 784 again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqCxng_noCx0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6ba654a-fe20-4447-e2cd-7413ebf1069f"
      },
      "source": [
        "decoded_images[1].size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk_CHCTsoGlt"
      },
      "source": [
        "Finally, we need to reshape the output vectors to get an estimation of the initial data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taU8GiKLOuFe"
      },
      "source": [
        "decoded_images_orig = numpy.reshape(decoded_images,newshape=(decoded_images.shape[0],28,28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hVR-Ohog-2u"
      },
      "source": [
        "We can display the original and reconstructed images of 5 random samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8FtjRDpO_lG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "aefd3fbd-f9ba-4fa9-ccd4-a5cc0b608de6"
      },
      "source": [
        "import matplotlib\n",
        "num_images_to_show = 5\n",
        "for im_ind in range(num_images_to_show):\n",
        "    plot_ind = im_ind*2 + 1\n",
        "    rand_ind = numpy.random.randint(low=0, high=x_train.shape[0])\n",
        "    matplotlib.pyplot.subplot(num_images_to_show, 2, plot_ind)\n",
        "    matplotlib.pyplot.imshow(x_train_orig[rand_ind, :, :], cmap=\"gray\")\n",
        "    matplotlib.pyplot.subplot(num_images_to_show, 2, plot_ind+1)\n",
        "    matplotlib.pyplot.imshow(decoded_images_orig[rand_ind, :, :], cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii4GN6WjkLbv"
      },
      "source": [
        "#Cette fonction combine toute les étapes précédentes et elle nous permet de modifier le nombre de neurones de la première couche pour modifier le taux de compression\n",
        "def autoencoder (nb_neurons,x_train, x_test):\n",
        "  x = tensorflow.keras.layers.Input(shape=(784), name=\"encoder_input\")\n",
        "  encoder_dense_layer1 = tensorflow.keras.layers.Dense(units=nb_neurons, name=\"encoder_dense_1\")(x)\n",
        "  encoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_1\")(encoder_dense_layer1)\n",
        "  encoder_dense_layer2 = tensorflow.keras.layers.Dense(units=2, name=\"encoder_dense_2\")(encoder_activ_layer1)\n",
        "  encoder_output = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_2\")(encoder_dense_layer2)\n",
        "  encoder = tensorflow.keras.models.Model(x, encoder_output, name=\"encoder_model\")\n",
        "  encoder.summary()\n",
        "  decoder_input = tensorflow.keras.layers.Input(shape=(2), name=\"decoder_input\")\n",
        "  decoder_dense_layer1 = tensorflow.keras.layers.Dense(units=nb_neurons, name=\"decoder_dense_1\")(decoder_input)\n",
        "  decoder_activ_layer1 =  tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_1\")(decoder_dense_layer1)\n",
        "  decoder_dense_layer2 = tensorflow.keras.layers.Dense(units=784, name=\"decoder_dense_2\")(decoder_activ_layer1)\n",
        "  decoder_output = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_2\")(decoder_dense_layer2)\n",
        "  decoder = tensorflow.keras.models.Model(decoder_input, decoder_output, name=\"decoder_model\")\n",
        "  decoder.summary()\n",
        "  ae_input = tensorflow.keras.layers.Input(shape=(784), name=\"AE_input\")\n",
        "  ae_encoder_output = encoder(ae_input)\n",
        "  ae_decoder_output = decoder(ae_encoder_output)\n",
        "  ae = tensorflow.keras.models.Model(ae_input, ae_decoder_output, name=\"AE\")\n",
        "  ae.summary()\n",
        "  ae.compile(loss='mse', optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.0005))\n",
        "  ae.fit(x_train, x_train, epochs=20, batch_size=256, shuffle=True, validation_data=(x_test, x_test))\n",
        "  encoded_images = encoder.predict(x_train)\n",
        "  decoded_images = decoder.predict(encoded_images)\n",
        "  encoded_images[1].size\n",
        "  decoded_images[1].size\n",
        "  decoded_images_orig = numpy.reshape(decoded_images,newshape=(decoded_images.shape[0],28,28))\n",
        "  return decoded_images_orig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhAm654dadBd"
      },
      "source": [
        "from math import log10, sqrt \n",
        "import tensorflow.image\n",
        "\n",
        "#Permet de calculer le PSNR\n",
        "\n",
        "def PSNR(original, compressed): \n",
        "    original = original.astype(numpy.float64)\n",
        "    compressed = compressed.astype(numpy.float64)\n",
        "    #print(original)\n",
        "    mse = numpy.mean((original - compressed) ** 2) \n",
        "    if(mse == 0):  # MSE is zero means no noise is present in the signal . \n",
        "                  # Therefore PSNR have no importance. \n",
        "        return 100\n",
        "    max_pixel = 255.0\n",
        "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
        " \n",
        "    return psnr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlE5Jr2LhdAo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bbc7b687-b640-49b9-f880-87178aaad0dc"
      },
      "source": [
        "average_PNSR = [] #Tableau des moyennes du PSNR sur plusieurs images\n",
        "prob=[] #Tableau de toutes les probabilités\n",
        "import matplotlib.pyplot as plt\n",
        "def show_images():\n",
        "  pnsr = 0\n",
        "  import matplotlib\n",
        "  num_images_to_show = 100\n",
        "  for im_ind in range(num_images_to_show):\n",
        "    plot_ind = im_ind*2 + 1\n",
        "    rand_ind = numpy.random.randint(low=0, high=x_train.shape[0])\n",
        "    pnsr += PSNR(x_train_orig[rand_ind, :, :], decoded_images_orig[rand_ind, :, :]) #Calcule le PSNR sur l'image originel et decodé\n",
        "  pnsr = (pnsr/num_images_to_show) #Calcule la moyenne de PSNR\n",
        "  average_PNSR.append(pnsr) \n",
        "x = []\n",
        "\n",
        "#Autoencode les images, calcule le PSNR et l'entropie\n",
        "for i in range (50, 600, 50): #i est le nombre de neurones pour varier le taux de compression \n",
        "  x.append(i)\n",
        "  decoded_images_orig = autoencoder(i,x_train, x_test)\n",
        "  prob.append(prob_entropy(decoded_images_orig))\n",
        "  show_images()\n",
        "  print(average_PNSR)\n",
        "y = average_PNSR\n",
        "\n",
        "#Affiche la moyenne des PSNR en fonction du taux de compression\n",
        "new_x = []\n",
        "for i in range(len(x)):\n",
        "  new_x.append(x[i]/784)\n",
        "print(new_x)\n",
        "plt.plot(new_x, y)\n",
        "plt.title(\"PNSR average\")\n",
        "plt.show()\n",
        "\n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_1 (Dense)      (None, 50)                39250     \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_1 (LeakyRe (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_2 (Dense)      (None, 2)                 102       \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_2 (LeakyRe (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 39,352\n",
            "Trainable params: 39,352\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_1 (Dense)      (None, 50)                150       \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_1 (LeakyRe (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_2 (Dense)      (None, 784)               39984     \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_2 (LeakyRe (None, 784)               0         \n",
            "=================================================================\n",
            "Total params: 40,134\n",
            "Trainable params: 40,134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"AE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "AE_input (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_model (Functional)   (None, 2)                 39352     \n",
            "_________________________________________________________________\n",
            "decoder_model (Functional)   (None, 784)               40134     \n",
            "=================================================================\n",
            "Total params: 79,486\n",
            "Trainable params: 79,486\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0647 - val_loss: 0.0569\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0559 - val_loss: 0.0552\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0550 - val_loss: 0.0545\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0544 - val_loss: 0.0538\n",
            "Epoch 5/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0539 - val_loss: 0.0533\n",
            "Epoch 6/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0534 - val_loss: 0.0527\n",
            "Epoch 7/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0530 - val_loss: 0.0524\n",
            "Epoch 8/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0526 - val_loss: 0.0520\n",
            "Epoch 9/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0522 - val_loss: 0.0516\n",
            "Epoch 10/20\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0518 - val_loss: 0.0513\n",
            "Epoch 11/20\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.0515 - val_loss: 0.0511\n",
            "Epoch 12/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0513 - val_loss: 0.0508\n",
            "Epoch 13/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0510 - val_loss: 0.0506\n",
            "Epoch 14/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0508 - val_loss: 0.0505\n",
            "Epoch 15/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0507 - val_loss: 0.0502\n",
            "Epoch 16/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0505 - val_loss: 0.0502\n",
            "Epoch 17/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0503 - val_loss: 0.0499\n",
            "Epoch 18/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0502 - val_loss: 0.0499\n",
            "Epoch 19/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0500 - val_loss: 0.0496\n",
            "Epoch 20/20\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 0.0499 - val_loss: 0.0495\n",
            "[61.61860087322625]\n",
            "Model: \"encoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_1 (Dense)      (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_1 (LeakyRe (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_2 (Dense)      (None, 2)                 202       \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_2 (LeakyRe (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 78,702\n",
            "Trainable params: 78,702\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_1 (Dense)      (None, 100)               300       \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_1 (LeakyRe (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_2 (Dense)      (None, 784)               79184     \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_2 (LeakyRe (None, 784)               0         \n",
            "=================================================================\n",
            "Total params: 79,484\n",
            "Trainable params: 79,484\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"AE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "AE_input (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_model (Functional)   (None, 2)                 78702     \n",
            "_________________________________________________________________\n",
            "decoder_model (Functional)   (None, 784)               79484     \n",
            "=================================================================\n",
            "Total params: 158,186\n",
            "Trainable params: 158,186\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0628 - val_loss: 0.0561\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0550 - val_loss: 0.0542\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0537 - val_loss: 0.0531\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0528 - val_loss: 0.0522\n",
            "Epoch 5/20\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0520 - val_loss: 0.0516\n",
            "Epoch 6/20\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0515 - val_loss: 0.0511\n",
            "Epoch 7/20\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0510 - val_loss: 0.0508\n",
            "Epoch 8/20\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0507 - val_loss: 0.0504\n",
            "Epoch 9/20\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0503 - val_loss: 0.0501\n",
            "Epoch 10/20\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0500 - val_loss: 0.0497\n",
            "Epoch 11/20\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0496 - val_loss: 0.0494\n",
            "Epoch 12/20\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0492 - val_loss: 0.0490\n",
            "Epoch 13/20\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0488 - val_loss: 0.0487\n",
            "Epoch 14/20\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0484 - val_loss: 0.0482\n",
            "Epoch 15/20\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 0.0481 - val_loss: 0.0481\n",
            "Epoch 16/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0478 - val_loss: 0.0477\n",
            "Epoch 17/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0475 - val_loss: 0.0476\n",
            "Epoch 18/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0473 - val_loss: 0.0472\n",
            "Epoch 19/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0471 - val_loss: 0.0471\n",
            "Epoch 20/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0469 - val_loss: 0.0470\n",
            "[61.61860087322625, 61.808571252826276]\n",
            "Model: \"encoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_1 (Dense)      (None, 150)               117750    \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_1 (LeakyRe (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_2 (Dense)      (None, 2)                 302       \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_2 (LeakyRe (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 118,052\n",
            "Trainable params: 118,052\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_1 (Dense)      (None, 150)               450       \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_1 (LeakyRe (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_2 (Dense)      (None, 784)               118384    \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_2 (LeakyRe (None, 784)               0         \n",
            "=================================================================\n",
            "Total params: 118,834\n",
            "Trainable params: 118,834\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"AE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "AE_input (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_model (Functional)   (None, 2)                 118052    \n",
            "_________________________________________________________________\n",
            "decoder_model (Functional)   (None, 784)               118834    \n",
            "=================================================================\n",
            "Total params: 236,886\n",
            "Trainable params: 236,886\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0619 - val_loss: 0.0563\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0554 - val_loss: 0.0549\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0544 - val_loss: 0.0540\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0536 - val_loss: 0.0533\n",
            "Epoch 5/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0529 - val_loss: 0.0526\n",
            "Epoch 6/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0522 - val_loss: 0.0520\n",
            "Epoch 7/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0514 - val_loss: 0.0512\n",
            "Epoch 8/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0505 - val_loss: 0.0502\n",
            "Epoch 9/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0494 - val_loss: 0.0492\n",
            "Epoch 10/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0486 - val_loss: 0.0485\n",
            "Epoch 11/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0481 - val_loss: 0.0479\n",
            "Epoch 12/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0476 - val_loss: 0.0476\n",
            "Epoch 13/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0473 - val_loss: 0.0473\n",
            "Epoch 14/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0470 - val_loss: 0.0469\n",
            "Epoch 15/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0467 - val_loss: 0.0468\n",
            "Epoch 16/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0465 - val_loss: 0.0465\n",
            "Epoch 17/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0463 - val_loss: 0.0463\n",
            "Epoch 18/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0461 - val_loss: 0.0462\n",
            "Epoch 19/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0460 - val_loss: 0.0462\n",
            "Epoch 20/20\n",
            "235/235 [==============================] - 3s 13ms/step - loss: 0.0458 - val_loss: 0.0458\n",
            "[61.61860087322625, 61.808571252826276, 62.14642892981332]\n",
            "Model: \"encoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_1 (Dense)      (None, 200)               157000    \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_1 (LeakyRe (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_2 (Dense)      (None, 2)                 402       \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_2 (LeakyRe (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 157,402\n",
            "Trainable params: 157,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_1 (Dense)      (None, 200)               600       \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_1 (LeakyRe (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_2 (Dense)      (None, 784)               157584    \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_2 (LeakyRe (None, 784)               0         \n",
            "=================================================================\n",
            "Total params: 158,184\n",
            "Trainable params: 158,184\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"AE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "AE_input (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_model (Functional)   (None, 2)                 157402    \n",
            "_________________________________________________________________\n",
            "decoder_model (Functional)   (None, 784)               158184    \n",
            "=================================================================\n",
            "Total params: 315,586\n",
            "Trainable params: 315,586\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0608 - val_loss: 0.0562\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0552 - val_loss: 0.0546\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0539 - val_loss: 0.0535\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0529 - val_loss: 0.0525\n",
            "Epoch 5/20\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0519 - val_loss: 0.0514\n",
            "Epoch 6/20\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0508 - val_loss: 0.0502\n",
            "Epoch 7/20\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0496 - val_loss: 0.0491\n",
            "Epoch 8/20\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0486 - val_loss: 0.0481\n",
            "Epoch 9/20\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0478 - val_loss: 0.0477\n",
            "Epoch 10/20\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0473 - val_loss: 0.0472\n",
            "Epoch 11/20\n",
            "235/235 [==============================] - 4s 17ms/step - loss: 0.0469 - val_loss: 0.0469\n",
            "Epoch 12/20\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0466 - val_loss: 0.0466\n",
            "Epoch 13/20\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0464 - val_loss: 0.0464\n",
            "Epoch 14/20\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0462 - val_loss: 0.0462\n",
            "Epoch 15/20\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0460 - val_loss: 0.0460\n",
            "Epoch 16/20\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0458 - val_loss: 0.0458\n",
            "Epoch 17/20\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0456 - val_loss: 0.0457\n",
            "Epoch 18/20\n",
            "235/235 [==============================] - 4s 16ms/step - loss: 0.0455 - val_loss: 0.0455\n",
            "Epoch 19/20\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0454 - val_loss: 0.0456\n",
            "Epoch 20/20\n",
            "235/235 [==============================] - 4s 15ms/step - loss: 0.0453 - val_loss: 0.0453\n",
            "[61.61860087322625, 61.808571252826276, 62.14642892981332, 62.02820990035524]\n",
            "Model: \"encoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_1 (Dense)      (None, 250)               196250    \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_1 (LeakyRe (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_2 (Dense)      (None, 2)                 502       \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_2 (LeakyRe (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 196,752\n",
            "Trainable params: 196,752\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_1 (Dense)      (None, 250)               750       \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_1 (LeakyRe (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_2 (Dense)      (None, 784)               196784    \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_2 (LeakyRe (None, 784)               0         \n",
            "=================================================================\n",
            "Total params: 197,534\n",
            "Trainable params: 197,534\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"AE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "AE_input (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_model (Functional)   (None, 2)                 196752    \n",
            "_________________________________________________________________\n",
            "decoder_model (Functional)   (None, 784)               197534    \n",
            "=================================================================\n",
            "Total params: 394,286\n",
            "Trainable params: 394,286\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "235/235 [==============================] - 4s 19ms/step - loss: 0.0599 - val_loss: 0.0554\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0548 - val_loss: 0.0543\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0537 - val_loss: 0.0533\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0528 - val_loss: 0.0525\n",
            "Epoch 5/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0518 - val_loss: 0.0514\n",
            "Epoch 6/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0504 - val_loss: 0.0498\n",
            "Epoch 7/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0490 - val_loss: 0.0485\n",
            "Epoch 8/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0481 - val_loss: 0.0479\n",
            "Epoch 9/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0476 - val_loss: 0.0473\n",
            "Epoch 10/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0471 - val_loss: 0.0470\n",
            "Epoch 11/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0468 - val_loss: 0.0467\n",
            "Epoch 12/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0465 - val_loss: 0.0466\n",
            "Epoch 13/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0463 - val_loss: 0.0464\n",
            "Epoch 14/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0461 - val_loss: 0.0461\n",
            "Epoch 15/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0458 - val_loss: 0.0460\n",
            "Epoch 16/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0457 - val_loss: 0.0458\n",
            "Epoch 17/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0455 - val_loss: 0.0456\n",
            "Epoch 18/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0454 - val_loss: 0.0454\n",
            "Epoch 19/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0452 - val_loss: 0.0454\n",
            "Epoch 20/20\n",
            "235/235 [==============================] - 4s 18ms/step - loss: 0.0451 - val_loss: 0.0451\n",
            "[61.61860087322625, 61.808571252826276, 62.14642892981332, 62.02820990035524, 62.06186572255942]\n",
            "Model: \"encoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_1 (Dense)      (None, 300)               235500    \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_1 (LeakyRe (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_2 (Dense)      (None, 2)                 602       \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_2 (LeakyRe (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 236,102\n",
            "Trainable params: 236,102\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_1 (Dense)      (None, 300)               900       \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_1 (LeakyRe (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_2 (Dense)      (None, 784)               235984    \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_2 (LeakyRe (None, 784)               0         \n",
            "=================================================================\n",
            "Total params: 236,884\n",
            "Trainable params: 236,884\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"AE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "AE_input (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_model (Functional)   (None, 2)                 236102    \n",
            "_________________________________________________________________\n",
            "decoder_model (Functional)   (None, 784)               236884    \n",
            "=================================================================\n",
            "Total params: 472,986\n",
            "Trainable params: 472,986\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "235/235 [==============================] - 8s 35ms/step - loss: 0.0598 - val_loss: 0.0552\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0541 - val_loss: 0.0532\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0526 - val_loss: 0.0520\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0514 - val_loss: 0.0509\n",
            "Epoch 5/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0503 - val_loss: 0.0497\n",
            "Epoch 6/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0493 - val_loss: 0.0489\n",
            "Epoch 7/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0485 - val_loss: 0.0481\n",
            "Epoch 8/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0477 - val_loss: 0.0474\n",
            "Epoch 9/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0471 - val_loss: 0.0469\n",
            "Epoch 10/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0467 - val_loss: 0.0466\n",
            "Epoch 11/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0464 - val_loss: 0.0465\n",
            "Epoch 12/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0462 - val_loss: 0.0462\n",
            "Epoch 13/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0460 - val_loss: 0.0461\n",
            "Epoch 14/20\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.0457 - val_loss: 0.0458\n",
            "Epoch 15/20\n",
            "235/235 [==============================] - 7s 29ms/step - loss: 0.0456 - val_loss: 0.0457\n",
            "Epoch 16/20\n",
            "235/235 [==============================] - 5s 23ms/step - loss: 0.0454 - val_loss: 0.0455\n",
            "Epoch 17/20\n",
            "235/235 [==============================] - 5s 22ms/step - loss: 0.0452 - val_loss: 0.0453\n",
            "Epoch 18/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0451 - val_loss: 0.0454\n",
            "Epoch 19/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0449 - val_loss: 0.0451\n",
            "Epoch 20/20\n",
            "235/235 [==============================] - 5s 21ms/step - loss: 0.0448 - val_loss: 0.0451\n",
            "[61.61860087322625, 61.808571252826276, 62.14642892981332, 62.02820990035524, 62.06186572255942, 61.85104600708866]\n",
            "Model: \"encoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_1 (Dense)      (None, 350)               274750    \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_1 (LeakyRe (None, 350)               0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_2 (Dense)      (None, 2)                 702       \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_2 (LeakyRe (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 275,452\n",
            "Trainable params: 275,452\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_1 (Dense)      (None, 350)               1050      \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_1 (LeakyRe (None, 350)               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_2 (Dense)      (None, 784)               275184    \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_2 (LeakyRe (None, 784)               0         \n",
            "=================================================================\n",
            "Total params: 276,234\n",
            "Trainable params: 276,234\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"AE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "AE_input (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_model (Functional)   (None, 2)                 275452    \n",
            "_________________________________________________________________\n",
            "decoder_model (Functional)   (None, 784)               276234    \n",
            "=================================================================\n",
            "Total params: 551,686\n",
            "Trainable params: 551,686\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0603 - val_loss: 0.0554\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0541 - val_loss: 0.0530\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0523 - val_loss: 0.0516\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0511 - val_loss: 0.0507\n",
            "Epoch 5/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0501 - val_loss: 0.0497\n",
            "Epoch 6/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0491 - val_loss: 0.0488\n",
            "Epoch 7/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0483 - val_loss: 0.0482\n",
            "Epoch 8/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0477 - val_loss: 0.0475\n",
            "Epoch 9/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0473 - val_loss: 0.0473\n",
            "Epoch 10/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0468 - val_loss: 0.0467\n",
            "Epoch 11/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0465 - val_loss: 0.0464\n",
            "Epoch 12/20\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.0462 - val_loss: 0.0462\n",
            "Epoch 13/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0459 - val_loss: 0.0458\n",
            "Epoch 14/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0456 - val_loss: 0.0455\n",
            "Epoch 15/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0454 - val_loss: 0.0454\n",
            "Epoch 16/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0452 - val_loss: 0.0451\n",
            "Epoch 17/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0449 - val_loss: 0.0449\n",
            "Epoch 18/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0448 - val_loss: 0.0448\n",
            "Epoch 19/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0446 - val_loss: 0.0447\n",
            "Epoch 20/20\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.0444 - val_loss: 0.0444\n",
            "[61.61860087322625, 61.808571252826276, 62.14642892981332, 62.02820990035524, 62.06186572255942, 61.85104600708866, 61.972438780171004]\n",
            "Model: \"encoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_1 (Dense)      (None, 400)               314000    \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_1 (LeakyRe (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_2 (Dense)      (None, 2)                 802       \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_2 (LeakyRe (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 314,802\n",
            "Trainable params: 314,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_1 (Dense)      (None, 400)               1200      \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_1 (LeakyRe (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_2 (Dense)      (None, 784)               314384    \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_2 (LeakyRe (None, 784)               0         \n",
            "=================================================================\n",
            "Total params: 315,584\n",
            "Trainable params: 315,584\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"AE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "AE_input (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_model (Functional)   (None, 2)                 314802    \n",
            "_________________________________________________________________\n",
            "decoder_model (Functional)   (None, 784)               315584    \n",
            "=================================================================\n",
            "Total params: 630,386\n",
            "Trainable params: 630,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0590 - val_loss: 0.0546\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0538 - val_loss: 0.0527\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.0522 - val_loss: 0.0516\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0513 - val_loss: 0.0508\n",
            "Epoch 5/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0505 - val_loss: 0.0501\n",
            "Epoch 6/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0496 - val_loss: 0.0493\n",
            "Epoch 7/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0487 - val_loss: 0.0485\n",
            "Epoch 8/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0480 - val_loss: 0.0478\n",
            "Epoch 9/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0474 - val_loss: 0.0474\n",
            "Epoch 10/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0470 - val_loss: 0.0469\n",
            "Epoch 11/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0466 - val_loss: 0.0465\n",
            "Epoch 12/20\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.0462 - val_loss: 0.0464\n",
            "Epoch 13/20\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.0459 - val_loss: 0.0459\n",
            "Epoch 14/20\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.0457 - val_loss: 0.0458\n",
            "Epoch 15/20\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.0454 - val_loss: 0.0455\n",
            "Epoch 16/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0452 - val_loss: 0.0452\n",
            "Epoch 17/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0451 - val_loss: 0.0451\n",
            "Epoch 18/20\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.0449 - val_loss: 0.0451\n",
            "Epoch 19/20\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.0447 - val_loss: 0.0449\n",
            "Epoch 20/20\n",
            "235/235 [==============================] - 6s 26ms/step - loss: 0.0445 - val_loss: 0.0447\n",
            "[61.61860087322625, 61.808571252826276, 62.14642892981332, 62.02820990035524, 62.06186572255942, 61.85104600708866, 61.972438780171004, 61.810950024692254]\n",
            "Model: \"encoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_1 (Dense)      (None, 450)               353250    \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_1 (LeakyRe (None, 450)               0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_2 (Dense)      (None, 2)                 902       \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_2 (LeakyRe (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 354,152\n",
            "Trainable params: 354,152\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_1 (Dense)      (None, 450)               1350      \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_1 (LeakyRe (None, 450)               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_2 (Dense)      (None, 784)               353584    \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_2 (LeakyRe (None, 784)               0         \n",
            "=================================================================\n",
            "Total params: 354,934\n",
            "Trainable params: 354,934\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"AE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "AE_input (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_model (Functional)   (None, 2)                 354152    \n",
            "_________________________________________________________________\n",
            "decoder_model (Functional)   (None, 784)               354934    \n",
            "=================================================================\n",
            "Total params: 709,086\n",
            "Trainable params: 709,086\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.0536 - val_loss: 0.0527\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 7s 30ms/step - loss: 0.0521 - val_loss: 0.0513\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0511 - val_loss: 0.0506\n",
            "Epoch 5/20\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.0505 - val_loss: 0.0500\n",
            "Epoch 6/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0497 - val_loss: 0.0493\n",
            "Epoch 7/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0488 - val_loss: 0.0486\n",
            "Epoch 8/20\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.0481 - val_loss: 0.0478\n",
            "Epoch 9/20\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.0475 - val_loss: 0.0473\n",
            "Epoch 10/20\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.0470 - val_loss: 0.0468\n",
            "Epoch 11/20\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.0466 - val_loss: 0.0465\n",
            "Epoch 12/20\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.0462 - val_loss: 0.0462\n",
            "Epoch 13/20\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.0459 - val_loss: 0.0458\n",
            "Epoch 14/20\n",
            "235/235 [==============================] - 8s 32ms/step - loss: 0.0456 - val_loss: 0.0456\n",
            "Epoch 15/20\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.0454 - val_loss: 0.0454\n",
            "Epoch 16/20\n",
            "235/235 [==============================] - 7s 32ms/step - loss: 0.0451 - val_loss: 0.0452\n",
            "Epoch 17/20\n",
            "235/235 [==============================] - 8s 32ms/step - loss: 0.0449 - val_loss: 0.0450\n",
            "Epoch 18/20\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.0447 - val_loss: 0.0447\n",
            "Epoch 19/20\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.0445 - val_loss: 0.0447\n",
            "Epoch 20/20\n",
            "235/235 [==============================] - 7s 31ms/step - loss: 0.0443 - val_loss: 0.0449\n",
            "[61.61860087322625, 61.808571252826276, 62.14642892981332, 62.02820990035524, 62.06186572255942, 61.85104600708866, 61.972438780171004, 61.810950024692254, 61.79396212800189]\n",
            "Model: \"encoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_1 (Dense)      (None, 500)               392500    \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_1 (LeakyRe (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_2 (Dense)      (None, 2)                 1002      \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_2 (LeakyRe (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 393,502\n",
            "Trainable params: 393,502\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_1 (Dense)      (None, 500)               1500      \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_1 (LeakyRe (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_2 (Dense)      (None, 784)               392784    \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_2 (LeakyRe (None, 784)               0         \n",
            "=================================================================\n",
            "Total params: 394,284\n",
            "Trainable params: 394,284\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"AE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "AE_input (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_model (Functional)   (None, 2)                 393502    \n",
            "_________________________________________________________________\n",
            "decoder_model (Functional)   (None, 784)               394284    \n",
            "=================================================================\n",
            "Total params: 787,786\n",
            "Trainable params: 787,786\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0599 - val_loss: 0.0553\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0546 - val_loss: 0.0538\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0534 - val_loss: 0.0524\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - 8s 34ms/step - loss: 0.0521 - val_loss: 0.0509\n",
            "Epoch 5/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0505 - val_loss: 0.0496\n",
            "Epoch 6/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0492 - val_loss: 0.0486\n",
            "Epoch 7/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0485 - val_loss: 0.0481\n",
            "Epoch 8/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0479 - val_loss: 0.0478\n",
            "Epoch 9/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0475 - val_loss: 0.0474\n",
            "Epoch 10/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0471 - val_loss: 0.0470\n",
            "Epoch 11/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0467 - val_loss: 0.0470\n",
            "Epoch 12/20\n",
            "235/235 [==============================] - 12s 51ms/step - loss: 0.0464 - val_loss: 0.0465\n",
            "Epoch 13/20\n",
            "235/235 [==============================] - 8s 34ms/step - loss: 0.0461 - val_loss: 0.0462\n",
            "Epoch 14/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0458 - val_loss: 0.0460\n",
            "Epoch 15/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0456 - val_loss: 0.0458\n",
            "Epoch 16/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0454 - val_loss: 0.0456\n",
            "Epoch 17/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0451 - val_loss: 0.0453\n",
            "Epoch 18/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0449 - val_loss: 0.0451\n",
            "Epoch 19/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0447 - val_loss: 0.0449\n",
            "Epoch 20/20\n",
            "235/235 [==============================] - 8s 33ms/step - loss: 0.0446 - val_loss: 0.0450\n",
            "[61.61860087322625, 61.808571252826276, 62.14642892981332, 62.02820990035524, 62.06186572255942, 61.85104600708866, 61.972438780171004, 61.810950024692254, 61.79396212800189, 61.670030592870134]\n",
            "Model: \"encoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_1 (Dense)      (None, 550)               431750    \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_1 (LeakyRe (None, 550)               0         \n",
            "_________________________________________________________________\n",
            "encoder_dense_2 (Dense)      (None, 2)                 1102      \n",
            "_________________________________________________________________\n",
            "encoder_leakyrelu_2 (LeakyRe (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 432,852\n",
            "Trainable params: 432,852\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"decoder_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_1 (Dense)      (None, 550)               1650      \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_1 (LeakyRe (None, 550)               0         \n",
            "_________________________________________________________________\n",
            "decoder_dense_2 (Dense)      (None, 784)               431984    \n",
            "_________________________________________________________________\n",
            "decoder_leakyrelu_2 (LeakyRe (None, 784)               0         \n",
            "=================================================================\n",
            "Total params: 433,634\n",
            "Trainable params: 433,634\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"AE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "AE_input (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "encoder_model (Functional)   (None, 2)                 432852    \n",
            "_________________________________________________________________\n",
            "decoder_model (Functional)   (None, 784)               433634    \n",
            "=================================================================\n",
            "Total params: 866,486\n",
            "Trainable params: 866,486\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.0592 - val_loss: 0.0546\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0537 - val_loss: 0.0525\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0520 - val_loss: 0.0513\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - 9s 38ms/step - loss: 0.0509 - val_loss: 0.0502\n",
            "Epoch 5/20\n",
            "235/235 [==============================] - 9s 36ms/step - loss: 0.0498 - val_loss: 0.0492\n",
            "Epoch 6/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0487 - val_loss: 0.0483\n",
            "Epoch 7/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0479 - val_loss: 0.0476\n",
            "Epoch 8/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0473 - val_loss: 0.0471\n",
            "Epoch 9/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0468 - val_loss: 0.0467\n",
            "Epoch 10/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0464 - val_loss: 0.0462\n",
            "Epoch 11/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0460 - val_loss: 0.0461\n",
            "Epoch 12/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0457 - val_loss: 0.0455\n",
            "Epoch 13/20\n",
            "235/235 [==============================] - 9s 37ms/step - loss: 0.0454 - val_loss: 0.0453\n",
            "Epoch 14/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0451 - val_loss: 0.0450\n",
            "Epoch 15/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0449 - val_loss: 0.0448\n",
            "Epoch 16/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0446 - val_loss: 0.0447\n",
            "Epoch 17/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0444 - val_loss: 0.0446\n",
            "Epoch 18/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0442 - val_loss: 0.0443\n",
            "Epoch 19/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0440 - val_loss: 0.0441\n",
            "Epoch 20/20\n",
            "235/235 [==============================] - 8s 36ms/step - loss: 0.0438 - val_loss: 0.0440\n",
            "[61.61860087322625, 61.808571252826276, 62.14642892981332, 62.02820990035524, 62.06186572255942, 61.85104600708866, 61.972438780171004, 61.810950024692254, 61.79396212800189, 61.670030592870134, 62.13632690875939]\n",
            "[0.06377551020408163, 0.12755102040816327, 0.1913265306122449, 0.25510204081632654, 0.31887755102040816, 0.3826530612244898, 0.44642857142857145, 0.5102040816326531, 0.5739795918367347, 0.6377551020408163, 0.701530612244898]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfGtQPrj9DbI"
      },
      "source": [
        "#Cette fonction permet de calculer les probabilités ainsi que l'entropy\n",
        "import cv2\n",
        "def prob_entropy(image):\n",
        "  prob=[]\n",
        "  histogram = cv2.calcHist([image],[0],None,[256],[0,255])\n",
        "  for elt in  histogram:\n",
        "    proba = elt/784\n",
        "    if proba ==0:\n",
        "      temp=0\n",
        "    else:\n",
        "      temp=-1*proba*(numpy.log(proba)/numpy.log(2))\n",
        "    prob.append(temp)\n",
        "  \n",
        "  sum_prob=numpy.sum(prob)\n",
        "  return sum_prob[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgB_jGqf2sPZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c437a62b-c28e-4a90-9f06-f2ecaa20f11f"
      },
      "source": [
        "#We know that no feature has 0 image\n",
        "from math import log2\n",
        "entropy = 0\n",
        " # in bits\n",
        "(x_train_orig, y_train), (x_test_orig, y_test) = tensorflow.keras.datasets.mnist.load_data()\n",
        "x_train_orig = x_train_orig.astype(\"float32\") / 255.0\n",
        "x_test_orig = x_test_orig.astype(\"float32\") / 255.0\n",
        "nbFeatureList = numpy.histogram(y_train)[0]  # Number of images for each value represented\n",
        "for nbFeature in nbFeatureList:\n",
        "  entropy -= nbFeature/60000 * log2(nbFeature/60000) # p_i = nbFeature_i /60000 \n",
        "print(entropy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.3198709267551876\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}